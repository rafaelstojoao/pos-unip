{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stanza in /home/rafaelstojoao/.local/lib/python3.7/site-packages (1.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.24.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (1.6.0)\n",
      "Requirement already satisfied: tqdm in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (4.48.2)\n",
      "Requirement already satisfied: protobuf in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (3.11.3)\n",
      "Requirement already satisfied: numpy in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (1.19.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.25.11)\n",
      "Requirement already satisfied: future in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from torch>=1.3.0->stanza) (0.18.2)\n",
      "Requirement already satisfied: setuptools in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from protobuf->stanza) (46.4.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install stanza\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 5.82MB/s]                    \n",
      "2020-10-24 08:15:34 INFO: Downloading default packages for language: pt (Portuguese)...\n",
      "2020-10-24 08:15:34 INFO: File exists: /home/rafaelstojoao/stanza_resources/pt/default.zip.\n",
      "2020-10-24 08:15:37 INFO: Finished downloading models and saved to /home/rafaelstojoao/stanza_resources.\n",
      "2020-10-24 08:15:37 INFO: Loading these models for language: pt (Portuguese):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | bosque  |\n",
      "| mwt       | bosque  |\n",
      "| pos       | bosque  |\n",
      "| lemma     | bosque  |\n",
      "| depparse  | bosque  |\n",
      "=======================\n",
      "\n",
      "2020-10-24 08:15:37 INFO: Use device: cpu\n",
      "2020-10-24 08:15:37 INFO: Loading: tokenize\n",
      "2020-10-24 08:15:37 INFO: Loading: mwt\n",
      "2020-10-24 08:15:37 INFO: Loading: pos\n",
      "2020-10-24 08:15:38 INFO: Loading: lemma\n",
      "2020-10-24 08:15:38 INFO: Loading: depparse\n",
      "2020-10-24 08:15:39 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('pt') # download do modelo na língua (corpus)\n",
    "nlp = stanza.Pipeline('pt') # inicialização do pipeline na lingua selecionada\n",
    "doc = nlp(\"Pele nunca foi o melhor jogador de futebol\") # construção de anotações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"Pele\",\n",
      "      \"lemma\": \"Pele\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"feats\": \"Gender=Fem|Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"nsubj\",\n",
      "      \"misc\": \"start_char=0|end_char=4\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"nunca\",\n",
      "      \"lemma\": \"nunca\",\n",
      "      \"upos\": \"ADV\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"advmod\",\n",
      "      \"misc\": \"start_char=5|end_char=10\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"foi\",\n",
      "      \"lemma\": \"ser\",\n",
      "      \"upos\": \"AUX\",\n",
      "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"cop\",\n",
      "      \"misc\": \"start_char=11|end_char=14\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"o\",\n",
      "      \"lemma\": \"o\",\n",
      "      \"upos\": \"DET\",\n",
      "      \"feats\": \"Definite=Def|Gender=Masc|Number=Sing|PronType=Art\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"det\",\n",
      "      \"misc\": \"start_char=15|end_char=16\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"melhor\",\n",
      "      \"lemma\": \"bom\",\n",
      "      \"upos\": \"ADJ\",\n",
      "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"amod\",\n",
      "      \"misc\": \"start_char=17|end_char=23\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \"jogador\",\n",
      "      \"lemma\": \"jogador\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
      "      \"head\": 0,\n",
      "      \"deprel\": \"root\",\n",
      "      \"misc\": \"start_char=24|end_char=31\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"de\",\n",
      "      \"lemma\": \"de\",\n",
      "      \"upos\": \"ADP\",\n",
      "      \"head\": 8,\n",
      "      \"deprel\": \"case\",\n",
      "      \"misc\": \"start_char=32|end_char=34\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"futebol\",\n",
      "      \"lemma\": \"futebol\",\n",
      "      \"upos\": \"NOUN\",\n",
      "      \"feats\": \"Gender=Masc|Number=Sing\",\n",
      "      \"head\": 6,\n",
      "      \"deprel\": \"nmod\",\n",
      "      \"misc\": \"start_char=35|end_char=42\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'to_dic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-128cc4f980a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# https://stanfordnlp.github.io/stanza/data_objects.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'to_dic'"
     ]
    }
   ],
   "source": [
    "print(doc.num_tokens)\n",
    "print(doc)\n",
    "\n",
    "# https://stanfordnlp.github.io/stanza/data_objects.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(doc.entities)\n",
    "# GPE é geographical political entities\n",
    "# doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-24 02:11:57 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| sentiment | sstplus |\n",
      "=======================\n",
      "\n",
      "2020-10-24 02:11:57 INFO: Use device: cpu\n",
      "2020-10-24 02:11:57 INFO: Loading: tokenize\n",
      "2020-10-24 02:11:57 INFO: Loading: sentiment\n",
      "2020-10-24 02:11:57 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
    "doc = nlp('I hate studying machine learning')\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(i, sentence.sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

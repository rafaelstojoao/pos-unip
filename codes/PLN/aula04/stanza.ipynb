{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stanza in /home/rafaelstojoao/.local/lib/python3.7/site-packages (1.1.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.24.0)\n",
      "Requirement already satisfied: torch>=1.3.0 in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (1.6.0)\n",
      "Requirement already satisfied: tqdm in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (4.48.2)\n",
      "Requirement already satisfied: protobuf in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (3.11.3)\n",
      "Requirement already satisfied: numpy in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from stanza) (1.19.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.25.11)\n",
      "Requirement already satisfied: future in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from torch>=1.3.0->stanza) (0.18.2)\n",
      "Requirement already satisfied: setuptools in /home/rafaelstojoao/.local/lib/python3.7/site-packages (from protobuf->stanza) (46.4.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install stanza\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.1.0.json: 122kB [00:00, 6.64MB/s]                    \n",
      "2020-10-24 09:20:21 INFO: Downloading default packages for language: en (English)...\n",
      "2020-10-24 09:20:23 INFO: File exists: /home/rafaelstojoao/stanza_resources/en/default.zip.\n",
      "2020-10-24 09:20:35 INFO: Finished downloading models and saved to /home/rafaelstojoao/stanza_resources.\n",
      "2020-10-24 09:20:35 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | ewt       |\n",
      "| pos       | ewt       |\n",
      "| lemma     | ewt       |\n",
      "| depparse  | ewt       |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2020-10-24 09:20:35 INFO: Use device: cpu\n",
      "2020-10-24 09:20:35 INFO: Loading: tokenize\n",
      "2020-10-24 09:20:35 INFO: Loading: pos\n",
      "2020-10-24 09:20:36 INFO: Loading: lemma\n",
      "2020-10-24 09:20:36 INFO: Loading: depparse\n",
      "2020-10-24 09:20:37 INFO: Loading: sentiment\n",
      "2020-10-24 09:20:39 INFO: Loading: ner\n",
      "2020-10-24 09:20:40 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "\n",
    "stanza.download('en') # download do modelo na língua (corpus)\n",
    "\n",
    "nlp = stanza.Pipeline('en') # inicialização do pipeline na lingua selecionada\n",
    "\n",
    "doc = nlp(\"John is spoiling my classes.\") # construção de anotações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"I\",\n",
      "      \"misc\": \"start_char=0|end_char=1\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"love\",\n",
      "      \"misc\": \"start_char=2|end_char=6\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"studying\",\n",
      "      \"misc\": \"start_char=7|end_char=15\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"machine\",\n",
      "      \"misc\": \"start_char=16|end_char=23\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"learning\",\n",
      "      \"misc\": \"start_char=24|end_char=32\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \".\",\n",
      "      \"misc\": \"start_char=32|end_char=33\"\n",
      "    }\n",
      "  ],\n",
      "  [\n",
      "    {\n",
      "      \"id\": 1,\n",
      "      \"text\": \"But\",\n",
      "      \"misc\": \"start_char=34|end_char=37\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 2,\n",
      "      \"text\": \"math\",\n",
      "      \"misc\": \"start_char=38|end_char=42\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 3,\n",
      "      \"text\": \"is\",\n",
      "      \"misc\": \"start_char=43|end_char=45\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 4,\n",
      "      \"text\": \"too\",\n",
      "      \"misc\": \"start_char=46|end_char=49\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 5,\n",
      "      \"text\": \"dificult\",\n",
      "      \"misc\": \"start_char=50|end_char=58\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 6,\n",
      "      \"text\": \",\",\n",
      "      \"misc\": \"start_char=58|end_char=59\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 7,\n",
      "      \"text\": \"I\",\n",
      "      \"misc\": \"start_char=60|end_char=61\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 8,\n",
      "      \"text\": \"hate\",\n",
      "      \"misc\": \"start_char=62|end_char=66\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 9,\n",
      "      \"text\": \"it\",\n",
      "      \"misc\": \"start_char=67|end_char=69\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": 10,\n",
      "      \"text\": \".\",\n",
      "      \"misc\": \"start_char=69|end_char=70\"\n",
      "    }\n",
      "  ]\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(doc.num_words)\n",
    "print(doc)\n",
    "\n",
    "# https://stanfordnlp.github.io/stanza/data_objects.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('John', 3, 'nsubj')\n",
      "('is', 3, 'aux')\n",
      "('spoiling', 0, 'root')\n",
      "('my', 5, 'nmod:poss')\n",
      "('classes', 3, 'obj')\n",
      "('.', 3, 'punct')\n"
     ]
    }
   ],
   "source": [
    "# print(doc.entities)\n",
    "# GPE é geographical political entities\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-24 09:28:09 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| sentiment | sstplus |\n",
      "=======================\n",
      "\n",
      "2020-10-24 09:28:09 INFO: Use device: cpu\n",
      "2020-10-24 09:28:09 INFO: Loading: tokenize\n",
      "2020-10-24 09:28:09 INFO: Loading: sentiment\n",
      "2020-10-24 09:28:11 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
    "\n",
    "doc = nlp('I love studying machine learning. But math is too dificult, I hate it.')\n",
    "\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(i, sentence.sentiment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

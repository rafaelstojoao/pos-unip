{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Não', 'se', 'pode', 'olhar', 'o', 'umbigo', 'e', 'contemplar', 'o', 'horizonte', 'ao', 'mesmo', 'tempo']\n"
     ]
    }
   ],
   "source": [
    "#tokenização\n",
    "\n",
    "import nltk\n",
    "\n",
    "texto = \"Não se pode olhar o umbigo e contemplar o horizonte ao mesmo tempo\"\n",
    "\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "tokens = tokenizer.tokenize(texto)\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Análise NOUN None\n",
      "\n",
      "\n",
      "de ADP adposition\n",
      "\n",
      "\n",
      "uma DET None\n",
      "\n",
      "\n",
      "frase NOUN None\n",
      "\n",
      "\n",
      "criada VERB None\n",
      "\n",
      "\n",
      "pelo DET None\n",
      "\n",
      "\n",
      "Rafael PROPN None\n",
      "\n",
      "\n",
      ". PUNCT punctuation\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    " \n",
    "    \n",
    "# @RAFAEL descobrir os tipos (TODOS) de tag do spacy\n",
    "    \n",
    "# python -m spacy download pt_core_news_sm\n",
    "# Mais corpus em: https://spacy.io/usage/models\n",
    "\n",
    "# pln = spacy.load('en_core_web_sm')\n",
    "pln = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "frase = pln(\"Análise de uma frase criada pelo Rafael.\")\n",
    "# frase = pln(\"sometimes I think I can do everything\")\n",
    "\n",
    "for token in frase:\n",
    "    print('\\n')\n",
    "    print(token.text, token.pos_,spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esse', 'é', 'um', 'teste', 'para', 'testar', 'se', 'tudo', 'está', 'bem']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "texto2 = \"Esse é um teste para testar se tudo está bem\"\n",
    "\n",
    "frase = pln(texto2)\n",
    "\n",
    "\n",
    "palavras = []\n",
    "tipos = []\n",
    "\n",
    "for token in frase:\n",
    "\n",
    "    if token.text not in palavras:\n",
    "        palavras.append(token.text)\n",
    "        tipos.append(token.pos_)\n",
    "        \n",
    "palavras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'AUX', 'DET', 'NOUN', 'SCONJ', 'VERB', 'SCONJ', 'PRON', 'AUX', 'ADV']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[400], [233], [226], [549], [420], [659], [216], [444], [557], [308]]\n",
      "[319, 238, 221, 320, 381, 303, 381, 319, 238, 219]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "palavrasEmNumeros = []\n",
    "tiposEmNumeros    = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for palavra in palavras:\n",
    "    valor = 0\n",
    "    for caracter in palavra:\n",
    "        valor += ord(caracter)\n",
    "#     print(valor)\n",
    "    palavrasEmNumeros.append([valor])\n",
    "\n",
    "    \n",
    "    \n",
    "for tipo in tipos:\n",
    "    valor = 0\n",
    "    for caracter in tipo:\n",
    "        valor += ord(caracter)\n",
    "#     print(valor)\n",
    "    tiposEmNumeros.append(valor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "print(palavrasEmNumeros)\n",
    "print(tiposEmNumeros)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ȧ\n",
      "[238]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "conjtoTreino = [palavrasEmNumeros,tiposEmNumeros]\n",
    "\n",
    "\n",
    "classificadorNaive = GaussianNB()\n",
    "classificadorNaive.fit(conjtoTreino[0],conjtoTreino[1])\n",
    "\n",
    "\n",
    "# print(chr(550))\n",
    "entradaTeste = [[550]]\n",
    "\n",
    "\n",
    "print(classificadorNaive.predict(entradaTeste))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

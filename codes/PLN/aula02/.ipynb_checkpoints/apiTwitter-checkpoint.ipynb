{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/twitter-data-in-python/\n",
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIkey= '2xmZzKzI5XSydWu7bF0nAuFOn'\n",
    "APIkeysecret= 'drzoukxLeVRnXGcqbfZehepnWClVS1gHWkg4jvBmG7l3Z5ZSp2'\n",
    "\n",
    "access_token= '1307181393479380993-bbejpwItu84p6KLSRdRTqT2Nmv4L49'\n",
    "access_token_secret= 'qxstwRWL7hF9vYKLND1rOaCIHDylz8extTN7LK60wP6Ms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(APIkey, APIkeysecret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitar\n",
    "# api.update_status(\"O Professor @rafaelstojoao √© o melhor do mundo!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "@babusantana falou tudo amor\n",
      "https://t.co/ynmbkbqlyy\n",
      "\n",
      "rt @1casalfalandu: n√£o quero um amor passageiro. quero um amor que fa√ßa planos, caminhe comigo e acima de tudo fique. ‚ô•Ô∏è https://t.co/hqctp‚Ä¶\n",
      "\n",
      "@golddtae @jktenshi gente oq rolou prlo amor de jesus\n",
      "\n",
      "foi amor e foi loucura ao mesmo tempo ü§§ü•∞\n",
      "\n",
      "rt @felipezando: pelo amor de deus algu√©m chama o conselho tutelar https://t.co/ovauou7ful\n",
      "\n",
      "@we_the_boyz meu amor lindo meu tudo te amo\n",
      "\n",
      "rt @queenbelulu: serkan bolat seguiu o t√°xi de eda yildiz para declarar seu amor por ela, est√£o ouvindo meus gritos? #sen√ßalkapƒ±mƒ± https://‚Ä¶\n",
      "\n",
      "@_soueumesmo_ opa, valeu \n",
      "@voleiorasteiro amor, comprei bombom!\n",
      "\n",
      "vou explodir de tanto amor\n",
      "\n",
      "[19/9 14:24] : vai quere outra vida\n",
      "[19/9 14:25] let√≠cia ‚ô°: vou nadaaa\n",
      "[19/9 14:25] let√≠cia ‚ô°: vida t√° gostosa meu‚Ä¶ https://t.co/ijdjgjbbgu\n",
      "\n",
      " Texto limpo...\n",
      "['[', '19/9', '14:24', ']', ':', 'vai', 'quere', 'outra', 'vida', '[', '19/9', '14:25', ']', 'let√≠cia', '‚ô°', ':', 'vou', 'nadaaa', '[', '19/9', '14:25', ']', 'let√≠cia', '‚ô°', ':', 'vida', 't√°', 'gostosa', 'meu‚Ä¶', 'https', ':', '//t.co/ijdjgjbbgu']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rafaelstojoao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "termoDeBusca = \"amor\" #√©  a classe do 'sentimento'\n",
    "a_partir_de = \"2020-09-19\"\n",
    "\n",
    "#O Cursor retorna um objeto que pode ser iterado. V√°rias informa√ß√µes podem ser extra√≠das, como: \n",
    "# o texto do tweet (conteudo)\n",
    "#o autor do tweet\n",
    "#quando foi publicado\n",
    "\n",
    "tweets = tw.Cursor(api.search, #vou fazer uma busca no api do Twitter\n",
    "              q=termoDeBusca, #com o termo que est√° na vari√°vel termoDeBusca\n",
    "              lang=\"pt\", #somente em portugues do Brasil\n",
    "              since=a_partir_de).items(10) #e a partir desta data na variavel a_partir_de\n",
    "                                     #.item(10) indica que s√≥ quer 10 tweets\n",
    "\n",
    "# tweets\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "for tweet in tweets:\n",
    "    strBuscada = str(tweet.text).lower()\n",
    "    \n",
    "    print('\\n'+strBuscada)\n",
    "    texto = strBuscada\n",
    "    tokens = tokenizer.tokenize(strBuscada)\n",
    "#     print(tokens)\n",
    "    \n",
    "    \n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "# print(stopwords.words(\"portuguese\"))\n",
    "        \n",
    "stpwords = set(stopwords.words(\"portuguese\"))\n",
    "textoLimpo = []\n",
    "\n",
    "for token in list(tokens):\n",
    "    if token not in stpwords:\n",
    "        textoLimpo.append(token)\n",
    "\n",
    "#         print(tokens)\n",
    "print('\\n Texto limpo...')\n",
    "print(textoLimpo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proximas etapas:\n",
    "## construir o bag of words  com a contagem ou import√¢ncia das palabras normalizadas e tokenizadas (calculo do tf-idf)\n",
    "\n",
    "##criar um dataset pandas com os resultados e a ultima coluna √© a classe (termoDeBusca)\n",
    "## utilizar classificadores variasdos e verificar qual tem a melhor acur√°cia\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>Localiza√ß√£o</th>\n",
       "      <th>Data</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kaka_ernandes</td>\n",
       "      <td>021</td>\n",
       "      <td>2020-09-19 17:23:32</td>\n",
       "      <td>EU QUERO OUTRA LIBERTADORES MARCOS BRAZ, VC ME...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>markinhos_w</td>\n",
       "      <td>Onde o Gremio estiver</td>\n",
       "      <td>2020-09-19 17:23:31</td>\n",
       "      <td>RT @drbuzatta: Tem jogador do Gr√™mio q jogou m...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RealAndre12</td>\n",
       "      <td></td>\n",
       "      <td>2020-09-19 17:23:31</td>\n",
       "      <td>Domenec est√° prestigiado no cargo, se perder a...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bmundim_</td>\n",
       "      <td></td>\n",
       "      <td>2020-09-19 17:23:25</td>\n",
       "      <td>@johamzin @Flamengo Acho q voc√™ tem que olhar ...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UC_Catolica</td>\n",
       "      <td>Las Condes, Santiago</td>\n",
       "      <td>2020-09-19 17:23:24</td>\n",
       "      <td>A Votar! #LosCruzados https://t.co/UxWF3pQ5iS</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kvicent_</td>\n",
       "      <td>rj</td>\n",
       "      <td>2020-09-19 17:23:23</td>\n",
       "      <td>eu quero se foda w foram campe√µes da libertado...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CosenzaGiuliano</td>\n",
       "      <td></td>\n",
       "      <td>2020-09-19 17:23:22</td>\n",
       "      <td>Braz: \\n\\n\"Todos que entraram em campo, com ex...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Xinildo</td>\n",
       "      <td></td>\n",
       "      <td>2020-09-19 17:23:21</td>\n",
       "      <td>RT @SaoPauloFC: üì∫ A transmiss√£o de LDU x S√£o P...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CanalZona14</td>\n",
       "      <td></td>\n",
       "      <td>2020-09-19 17:23:19</td>\n",
       "      <td>Pro Corinthians talvez foi o caso de dar um pa...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atglua</td>\n",
       "      <td></td>\n",
       "      <td>2020-09-19 17:23:17</td>\n",
       "      <td>RT @SaoPauloFC: üì∫ A transmiss√£o de LDU x S√£o P...</td>\n",
       "      <td>libertadores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Nome            Localiza√ß√£o                Data  \\\n",
       "0    kaka_ernandes                   021  2020-09-19 17:23:32   \n",
       "1      markinhos_w  Onde o Gremio estiver 2020-09-19 17:23:31   \n",
       "2      RealAndre12                        2020-09-19 17:23:31   \n",
       "3         bmundim_                        2020-09-19 17:23:25   \n",
       "4      UC_Catolica   Las Condes, Santiago 2020-09-19 17:23:24   \n",
       "5         kvicent_                     rj 2020-09-19 17:23:23   \n",
       "6  CosenzaGiuliano                        2020-09-19 17:23:22   \n",
       "7          Xinildo                        2020-09-19 17:23:21   \n",
       "8      CanalZona14                        2020-09-19 17:23:19   \n",
       "9           atglua                        2020-09-19 17:23:17   \n",
       "\n",
       "                                               Tweet        classe  \n",
       "0  EU QUERO OUTRA LIBERTADORES MARCOS BRAZ, VC ME...  libertadores  \n",
       "1  RT @drbuzatta: Tem jogador do Gr√™mio q jogou m...  libertadores  \n",
       "2  Domenec est√° prestigiado no cargo, se perder a...  libertadores  \n",
       "3  @johamzin @Flamengo Acho q voc√™ tem que olhar ...  libertadores  \n",
       "4      A Votar! #LosCruzados https://t.co/UxWF3pQ5iS  libertadores  \n",
       "5  eu quero se foda w foram campe√µes da libertado...  libertadores  \n",
       "6  Braz: \\n\\n\"Todos que entraram em campo, com ex...  libertadores  \n",
       "7  RT @SaoPauloFC: üì∫ A transmiss√£o de LDU x S√£o P...  libertadores  \n",
       "8  Pro Corinthians talvez foi o caso de dar um pa...  libertadores  \n",
       "9  RT @SaoPauloFC: üì∫ A transmiss√£o de LDU x S√£o P...  libertadores  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweets = tw.Cursor(api.search, \n",
    "                           q=termoDeBusca,\n",
    "                           lang=\"pt\",).items(10)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "localizacao = [[tweet.user.screen_name, tweet.user.location, tweet.created_at,tweet.text,termoDeBusca] for tweet in tweets]\n",
    "pdTweet = pd.DataFrame(data=localizacao, columns=['Nome', \"Localiza√ß√£o\",'Data','Tweet','classe'])\n",
    "\n",
    "pdTweet\n",
    " \n",
    "\n",
    "    \n",
    "    \n",
    "#     tweetsSobreAUnip = []\n",
    "# for tweet in tweets:\n",
    "#     tweetsSobreAUnip.append([tweet.text,'unip'])\n",
    "# #       print('\\n'+str(tweet.text))\n",
    "    \n",
    "# pdTweet = pd.DataFrame(data=tweetsSobreAUnip,columns=['tweet','tema'])\n",
    "# pdTweet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## com os tweets em m√£os, agora √© s√≥ normalizar, fazer a tokeniza√ß√£o/stemmiza√ß√£o, remover stopwords criar o modelo de classifica√ß√£o e voilat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E se a gente mudar o tema para palavras de sentimentos?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

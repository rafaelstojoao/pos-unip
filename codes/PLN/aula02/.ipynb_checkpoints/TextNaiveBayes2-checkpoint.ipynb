{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Não', 'se', 'pode', 'olhar', 'o', 'umbigo', 'e', 'contemplar', 'o', 'horizonte', 'ao', 'mesmo', 'tempo']\n"
     ]
    }
   ],
   "source": [
    "#tokenização\n",
    "\n",
    "import nltk\n",
    "\n",
    "texto = \"Não se pode olhar o umbigo e contemplar o horizonte ao mesmo tempo\"\n",
    "# classeFrases = [0,2,1,1]\n",
    "\n",
    "#0: motivacional\n",
    "#1: espirita\n",
    "#2: comédia\n",
    "\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(texto)\n",
    "print(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Não</th>\n",
       "      <th>se</th>\n",
       "      <th>pode</th>\n",
       "      <th>olhar</th>\n",
       "      <th>o</th>\n",
       "      <th>umbigo</th>\n",
       "      <th>e</th>\n",
       "      <th>contemplar</th>\n",
       "      <th>o</th>\n",
       "      <th>horizonte</th>\n",
       "      <th>ao</th>\n",
       "      <th>mesmo</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Não se pode olhar  o umbigo  e contemplar  o horizonte ao mesmo tempo\n",
       "0   1  1    1     1  1      1  1          1  1         1  1     1     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VETORIZAÇÃO  BoW\n",
    "#one hot encoding\n",
    "#ato de converter as frases em vetores com 1s e 0s para indicar a ocorrência \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# pd.columns = itemsMaisFrequentes\n",
    "ds = pd.DataFrame(columns=tokens)\n",
    "\n",
    "ocorrencias =[]\n",
    "for item in ds:\n",
    "        if item in tokens:\n",
    "            ocorrencias.append('1')\n",
    "        else:\n",
    "            ocorrencias.append('0')\n",
    "# ocorrencias   \n",
    "\n",
    "serie = pd.Series(ocorrencias, index = ds.columns)\n",
    "ds = ds.append(serie, ignore_index=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note quantas vezes o termo \"o\" aparece. Ele traz alguma contribuição?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Não</th>\n",
       "      <th>se</th>\n",
       "      <th>pode</th>\n",
       "      <th>olhar</th>\n",
       "      <th>o</th>\n",
       "      <th>umbigo</th>\n",
       "      <th>e</th>\n",
       "      <th>contemplar</th>\n",
       "      <th>horizonte</th>\n",
       "      <th>ao</th>\n",
       "      <th>mesmo</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Não se pode olhar  o umbigo  e contemplar horizonte ao mesmo tempo\n",
       "0   1  1    1     1  1      1  1          1         1  1     1     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uma estratégia é remover os stopwords\n",
    "#ou construir um set()\n",
    "\n",
    "palavras = []\n",
    "for token in list(tokens):\n",
    "    if token not in palavras:\n",
    "        palavras.append(token)\n",
    "#         print(token)\n",
    "    \n",
    "\n",
    "\n",
    "ds = pd.DataFrame(columns=palavras)\n",
    "ds\n",
    "\n",
    "\n",
    "ocorrencias =[]\n",
    "for item in ds:\n",
    "        if item in palavras:\n",
    "            ocorrencias.append('1')\n",
    "        else:\n",
    "            ocorrencias.append('0')\n",
    "# ocorrencias   \n",
    "\n",
    "serie = pd.Series(ocorrencias, index = ds.columns)\n",
    "ds = ds.append(serie, ignore_index=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rafaelstojoao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words(\"portuguese\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Não', 'se', 'pode', 'olhar', 'o', 'umbigo', 'e', 'contemplar', 'o', 'horizonte', 'ao', 'mesmo', 'tempo']\n",
      "['Não', 'pode', 'olhar', 'umbigo', 'contemplar', 'horizonte', 'tempo']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Não</th>\n",
       "      <th>pode</th>\n",
       "      <th>olhar</th>\n",
       "      <th>umbigo</th>\n",
       "      <th>contemplar</th>\n",
       "      <th>horizonte</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Não pode olhar umbigo contemplar horizonte tempo\n",
       "0   1    1     1      1          1         1     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textoLimpo = []\n",
    "stpwords = set(stopwords.words(\"portuguese\"))\n",
    "\n",
    "\n",
    "for token in list(tokens):\n",
    "    if token not in stpwords:\n",
    "        textoLimpo.append(token)\n",
    "print(tokens)\n",
    "print(textoLimpo)\n",
    "  \n",
    "    \n",
    "ds = pd.DataFrame(columns=textoLimpo)\n",
    "ds\n",
    "\n",
    "\n",
    "ocorrencias =[]\n",
    "for item in ds:\n",
    "        if item in textoLimpo:\n",
    "            ocorrencias.append('1')\n",
    "        else:\n",
    "            ocorrencias.append('0')\n",
    "\n",
    "serie = pd.Series(ocorrencias, index = ds.columns)\n",
    "ds = ds.append(serie, ignore_index=True)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW via TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF(term frequency — inverse document frequency) é um método estatístico utilizado para avaliar a importância de uma palavra em determinado documento.\n",
    "\n",
    "\n",
    "TF (Term frequency): Quantidade de ocorrências de uma palavra em um texto, divida pelo número total de palavras do texto.\n",
    "\n",
    "\n",
    "\n",
    "ITF (Inverse Term Frequency): Quantidade de vezes que a palavra ocorre em um texto, dividida pela quantidade de frases (documentos) que tem o termo\n",
    "\n",
    "\n",
    "TF-IDF = TF*IDF\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "frasesPositivas = ['Que produto bom',\n",
    "                   'Muito bom',\n",
    "                   'Adorei',\n",
    "                   'Com certeza compraria novamente',\n",
    "                   'Gostei da qualidade do produto',\n",
    "                   'Adorei que chegou cedo',\n",
    "                   'Entrega rápida',\n",
    "                   'Qualidade excelente',\n",
    "                   'Produto de qualidade'\n",
    "                  ]\n",
    "\n",
    "\n",
    "\n",
    "frasesNegativas = ['Péssimo acabamento',\n",
    "                   'Quebrou com 1 semana de uso',\n",
    "                   'Não recomendo',\n",
    "                   'produto apresentou defeito'\n",
    "                   'produto fraco',\n",
    "                   'não vale a pena',\n",
    "                   'Baixa durabilidade',\n",
    "                   'veio com defeito',\n",
    "                   'Entrega demorou muito'\n",
    "                  ]\n",
    "#naturalmente essa base de dados é pequena demais para compor um classificador com precisão \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adorei</th>\n",
       "      <th>bom</th>\n",
       "      <th>cedo</th>\n",
       "      <th>certeza</th>\n",
       "      <th>chegou</th>\n",
       "      <th>com</th>\n",
       "      <th>compraria</th>\n",
       "      <th>da</th>\n",
       "      <th>de</th>\n",
       "      <th>do</th>\n",
       "      <th>entrega</th>\n",
       "      <th>excelente</th>\n",
       "      <th>gostei</th>\n",
       "      <th>muito</th>\n",
       "      <th>novamente</th>\n",
       "      <th>produto</th>\n",
       "      <th>qualidade</th>\n",
       "      <th>que</th>\n",
       "      <th>rápida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.523742</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.602368</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.763965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.495159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.495159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363629</td>\n",
       "      <td>0.363629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.456266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.540205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.540205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456266</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509365</td>\n",
       "      <td>0.509365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adorei       bom      cedo  certeza    chegou  com  compraria        da  \\\n",
       "0  0.000000  0.602368  0.000000      0.0  0.000000  0.0        0.0  0.000000   \n",
       "1  0.000000  0.645257  0.000000      0.0  0.000000  0.0        0.0  0.000000   \n",
       "2  1.000000  0.000000  0.000000      0.0  0.000000  0.0        0.0  0.000000   \n",
       "3  0.000000  0.000000  0.000000      0.5  0.000000  0.5        0.5  0.000000   \n",
       "4  0.000000  0.000000  0.000000      0.0  0.000000  0.0        0.0  0.495159   \n",
       "5  0.456266  0.000000  0.540205      0.0  0.540205  0.0        0.0  0.000000   \n",
       "6  0.000000  0.000000  0.000000      0.0  0.000000  0.0        0.0  0.000000   \n",
       "7  0.000000  0.000000  0.000000      0.0  0.000000  0.0        0.0  0.000000   \n",
       "8  0.000000  0.000000  0.000000      0.0  0.000000  0.0        0.0  0.000000   \n",
       "\n",
       "         de        do   entrega  excelente    gostei     muito  novamente  \\\n",
       "0  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000        0.0   \n",
       "1  0.000000  0.000000  0.000000   0.000000  0.000000  0.763965        0.0   \n",
       "2  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000        0.0   \n",
       "3  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000        0.5   \n",
       "4  0.000000  0.495159  0.000000   0.000000  0.495159  0.000000        0.0   \n",
       "5  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000        0.0   \n",
       "6  0.000000  0.000000  0.707107   0.000000  0.000000  0.000000        0.0   \n",
       "7  0.000000  0.000000  0.000000   0.806007  0.000000  0.000000        0.0   \n",
       "8  0.693609  0.000000  0.000000   0.000000  0.000000  0.000000        0.0   \n",
       "\n",
       "    produto  qualidade       que    rápida  \n",
       "0  0.523742   0.000000  0.602368  0.000000  \n",
       "1  0.000000   0.000000  0.000000  0.000000  \n",
       "2  0.000000   0.000000  0.000000  0.000000  \n",
       "3  0.000000   0.000000  0.000000  0.000000  \n",
       "4  0.363629   0.363629  0.000000  0.000000  \n",
       "5  0.000000   0.000000  0.456266  0.000000  \n",
       "6  0.000000   0.000000  0.000000  0.707107  \n",
       "7  0.000000   0.591906  0.000000  0.000000  \n",
       "8  0.509365   0.509365  0.000000  0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculo de importâncias para frases positivas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "valores = tfidf.fit_transform(frasesPositivas)\n",
    "\n",
    "atributos = tfidf.get_feature_names()\n",
    "\n",
    "ds = pd.DataFrame(valores.toarray(),columns = atributos)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acabamento</th>\n",
       "      <th>apresentou</th>\n",
       "      <th>baixa</th>\n",
       "      <th>com</th>\n",
       "      <th>de</th>\n",
       "      <th>defeito</th>\n",
       "      <th>defeitoproduto</th>\n",
       "      <th>demorou</th>\n",
       "      <th>durabilidade</th>\n",
       "      <th>entrega</th>\n",
       "      <th>...</th>\n",
       "      <th>não</th>\n",
       "      <th>pena</th>\n",
       "      <th>produto</th>\n",
       "      <th>péssimo</th>\n",
       "      <th>quebrou</th>\n",
       "      <th>recomendo</th>\n",
       "      <th>semana</th>\n",
       "      <th>uso</th>\n",
       "      <th>vale</th>\n",
       "      <th>veio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386479</td>\n",
       "      <td>0.461149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461149</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.461149</td>\n",
       "      <td>0.461149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.76643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509814</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.509814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.608313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   acabamento  apresentou     baixa       com        de   defeito  \\\n",
       "0    0.707107         0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "1    0.000000         0.0  0.000000  0.386479  0.461149  0.000000   \n",
       "2    0.000000         0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "3    0.000000         0.5  0.000000  0.000000  0.000000  0.000000   \n",
       "4    0.000000         0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "5    0.000000         0.0  0.707107  0.000000  0.000000  0.000000   \n",
       "6    0.000000         0.0  0.000000  0.509814  0.000000  0.608313   \n",
       "7    0.000000         0.0  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "   defeitoproduto  demorou  durabilidade  entrega  ...       não      pena  \\\n",
       "0             0.0  0.00000      0.000000  0.00000  ...  0.000000  0.000000   \n",
       "1             0.0  0.00000      0.000000  0.00000  ...  0.000000  0.000000   \n",
       "2             0.0  0.00000      0.000000  0.00000  ...  0.642328  0.000000   \n",
       "3             0.5  0.00000      0.000000  0.00000  ...  0.000000  0.000000   \n",
       "4             0.0  0.00000      0.000000  0.00000  ...  0.509814  0.608313   \n",
       "5             0.0  0.00000      0.707107  0.00000  ...  0.000000  0.000000   \n",
       "6             0.0  0.00000      0.000000  0.00000  ...  0.000000  0.000000   \n",
       "7             0.0  0.57735      0.000000  0.57735  ...  0.000000  0.000000   \n",
       "\n",
       "   produto   péssimo   quebrou  recomendo    semana       uso      vale  \\\n",
       "0      0.0  0.707107  0.000000    0.00000  0.000000  0.000000  0.000000   \n",
       "1      0.0  0.000000  0.461149    0.00000  0.461149  0.461149  0.000000   \n",
       "2      0.0  0.000000  0.000000    0.76643  0.000000  0.000000  0.000000   \n",
       "3      0.5  0.000000  0.000000    0.00000  0.000000  0.000000  0.000000   \n",
       "4      0.0  0.000000  0.000000    0.00000  0.000000  0.000000  0.608313   \n",
       "5      0.0  0.000000  0.000000    0.00000  0.000000  0.000000  0.000000   \n",
       "6      0.0  0.000000  0.000000    0.00000  0.000000  0.000000  0.000000   \n",
       "7      0.0  0.000000  0.000000    0.00000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       veio  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  0.000000  \n",
       "5  0.000000  \n",
       "6  0.608313  \n",
       "7  0.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculo de importâncias para frases negativas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "valores = tfidf.fit_transform(frasesNegativas)\n",
    "\n",
    "atributos = tfidf.get_feature_names()\n",
    "\n",
    "ds = pd.DataFrame(valores.toarray(),columns = atributos)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faltou 1, não?   a contagem de tokens.\n",
    "\n",
    "## Implemente a contagem de tokens e aplique um classificador para treinar um modelo de frases positivas\n",
    "\n",
    "\n",
    "## Outro modelo de frases negativas\n",
    "\n",
    "## por fim classifique a frase:\n",
    "\n",
    "\"Eu não compro essa porcaria de iphone nunca mais, quebrou rápido demais\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#um Classificador Naive Bayes não é capaz de lidar com valores textuais\n",
    "#a estratégia é converter as palavras para valores discretos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizar:  Colocar todos elementos em caixa baixa\n",
    "#tokenizar\n",
    "#remover stopwords\n",
    "\n",
    "#remover palavras que comparecem nas duas bases de dados\n",
    "\n",
    "\n",
    "# # restante do codigo\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# classificador = MultinomialNB()\n",
    "# classificador.fit(conjuntoDeTreino, Classes)\n",
    "\n",
    "\n",
    "\n",
    "#VOCÊ tem DUAS opções:  \n",
    "#1) Se divertir\n",
    "#2) utilizar a  CountVectorizer da sklearn.feature_extraction.text\n",
    "\n",
    "\n",
    "#A quantidade de caracteres/palavras dos comentários positivos e negativos pode ser uma forma de análise?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Que',\n",
       " 'produto',\n",
       " 'bom',\n",
       " 'Muito',\n",
       " 'bom',\n",
       " 'Muito',\n",
       " 'bom',\n",
       " 'Muito',\n",
       " 'bom',\n",
       " 'Muito',\n",
       " 'bom',\n",
       " 'Muito',\n",
       " 'bom',\n",
       " 'Muito',\n",
       " 'bom',\n",
       " 'Muito',\n",
       " 'bom',\n",
       " 'Adorei',\n",
       " 'Adorei',\n",
       " 'Adorei',\n",
       " 'Adorei',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Com',\n",
       " 'certeza',\n",
       " 'compraria',\n",
       " 'novamente',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Gostei',\n",
       " 'da',\n",
       " 'qualidade',\n",
       " 'do',\n",
       " 'produto',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Adorei',\n",
       " 'que',\n",
       " 'chegou',\n",
       " 'cedo',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Entrega',\n",
       " 'rápida',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Qualidade',\n",
       " 'excelente',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'Produto',\n",
       " 'de',\n",
       " 'qualidade']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @JoãoHenrique code\n",
    "def limpa_texto(conjuntoDefrases): \n",
    "    texto = '' \n",
    "    list_stop_word = stopwords.words(\"portuguese\") \n",
    "    tokenizer = nltk.tokenize.TreebankWordTokenizer() \n",
    "    \n",
    "    \n",
    "    for frase in list(conjuntoDefrases):\n",
    "        tokensDaFrase = tokenizer.tokenize(frase) \n",
    "\n",
    "        for palavra in x:\n",
    "            if palavra not in list_stop_word: \n",
    "#                 print(x)\n",
    "                texto = texto + ' ' + x \n",
    "    \n",
    "    \n",
    "            \n",
    "    return frase_limpa \n",
    "\n",
    "\n",
    "\n",
    "limpa_texto(frasesPositivas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

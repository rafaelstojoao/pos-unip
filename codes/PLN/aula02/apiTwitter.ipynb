{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.earthdatascience.org/courses/use-data-open-source-python/intro-to-apis/twitter-data-in-python/\n",
    "import os\n",
    "import tweepy as tw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "APIkey= '2xmZzKzI5XSydWu7bF0nAuFOn'\n",
    "APIkeysecret= 'drzoukxLeVRnXGcqbfZehepnWClVS1gHWkg4jvBmG7l3Z5ZSp2'\n",
    "\n",
    "access_token= '1307181393479380993-bbejpwItu84p6KLSRdRTqT2Nmv4L49'\n",
    "access_token_secret= 'qxstwRWL7hF9vYKLND1rOaCIHDylz8extTN7LK60wP6Ms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tw.OAuthHandler(APIkey, APIkeysecret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitar\n",
    "# api.update_status(\"O Professor @rafaelstojoao Ã© o melhor do mundo!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rt @ficantesfalandu: me estressa, me irrita mas Ã© amor da minha vida todinha ğŸ˜¤â¤ï¸ğŸ™„ğŸ‘©â€â¤ï¸â€ğŸ’‹â€ğŸ‘¨\n",
      "\n",
      "3 anos de muito amor! https://t.co/ukfth6mmjj\n",
      "\n",
      "rt @ricfazeres: obrigado a todos pelo apoio e carinho.vocÃªs tÃªm sido o ombro amigo com tanta mensagem e preocupaÃ§Ã£o ğŸ˜”ğŸ™ processo:continuo aâ€¦\n",
      "\n",
      "rt @zeca_dirceu: o patrono da educaÃ§Ã£o brasileira, nossa honrado paulo freire, completaria hoje 99 anos. ele dedicou grande parte de sua viâ€¦\n",
      "\n",
      "ganhei sorvete e chocolate do meu amor que na verdade nÃ£o Ã© meu\n",
      "\n",
      "@iaylawaifu vc Ã© um amor de pessoa ğŸ’• e maravilhosa\n",
      "\n",
      "@gustavopowkk nada amor, pode deixar\n",
      "\n",
      "rt @gabrielraposo_1: e a minha namorada que decidiu me dar uma alianÃ§a no dia que a gnt estava saindo pra jantar pois eu iria dar uma alianâ€¦\n",
      "\n",
      "rt @itsbabyibo: xiao zhan nÃ£o cansa de ser o amor da minha vida https://t.co/loifojalw8\n",
      "\n",
      "@aphrodtism obrigado amor...\n",
      "\n",
      " Texto limpo...\n",
      "['@', 'aphrodtism', 'obrigado', 'amor', '...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/rafaelstojoao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "termoDeBusca = \"amor\" #Ã©  a classe do 'sentimento'\n",
    "a_partir_de = \"2020-09-19\"\n",
    "\n",
    "#O Cursor retorna um objeto que pode ser iterado. VÃ¡rias informaÃ§Ãµes podem ser extraÃ­das, como: \n",
    "# o texto do tweet (conteudo)\n",
    "#o autor do tweet\n",
    "#quando foi publicado\n",
    "\n",
    "tweets = tw.Cursor(api.search, #vou fazer uma busca no api do Twitter\n",
    "              q=termoDeBusca, #com o termo que estÃ¡ na variÃ¡vel termoDeBusca\n",
    "              lang=\"pt\", #somente em portugues do Brasil\n",
    "              since=a_partir_de).items(10) #e a partir desta data na variavel a_partir_de\n",
    "                                     #.item(10) indica que sÃ³ quer 10 tweets\n",
    "\n",
    "# tweets\n",
    "\n",
    "\n",
    "\n",
    "import nltk\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "for tweet in tweets:\n",
    "    strBuscada = str(tweet.text).lower()\n",
    "    \n",
    "    print('\\n'+strBuscada)\n",
    "    texto = strBuscada\n",
    "    tokens = tokenizer.tokenize(strBuscada)\n",
    "#     print(tokens)\n",
    "    \n",
    "    \n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "# print(stopwords.words(\"portuguese\"))\n",
    "        \n",
    "stpwords = set(stopwords.words(\"portuguese\"))\n",
    "textoLimpo = []\n",
    "\n",
    "for token in list(tokens):\n",
    "    if token not in stpwords:\n",
    "        textoLimpo.append(token)\n",
    "\n",
    "#         print(tokens)\n",
    "print('\\n Texto limpo...')\n",
    "print(textoLimpo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0047dc0f3e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     tweets = tw.Cursor(api.search, #vou fazer uma busca no api do Twitter\n\u001b[0m\u001b[1;32m     13\u001b[0m               \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermoDeBusca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#com o termo que estÃ¡ na variÃ¡vel termoDeBusca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#somente em portugues do Brasil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tw' is not defined"
     ]
    }
   ],
   "source": [
    "# termo de busca\n",
    "arrayTermosDeBusca = ['amor','Ã³dio','revolta','perdÃ£o']\n",
    "# dois termos de busca sobre sentimentos positivos\n",
    "#dois termos de busca sobre sentimentos negativos\n",
    "\n",
    "todosTweets = []\n",
    "for termo in arrayTermosDeBusca:\n",
    "    termoDeBusca = termo #Ã©  a classe do 'sentimento'\n",
    "    a_partir_de = \"2020-09-19\"\n",
    "\n",
    "    \n",
    "    tweets = tw.Cursor(api.search, #vou fazer uma busca no api do Twitter\n",
    "              q=termoDeBusca, #com o termo que estÃ¡ na variÃ¡vel termoDeBusca\n",
    "              lang=\"pt\", #somente em portugues do Brasil\n",
    "              since=a_partir_de).items(10) #e a partir desta data na variavel a_partir_de\n",
    "\n",
    "\n",
    "\n",
    "    localizacao = localizacao + [[tweet.text,termoDeBusca] for tweet in tweets]   \n",
    "    pdTweet = pd.DataFrame(data=localizacao, columns=['Tweet','classe'])\n",
    "\n",
    "pdTweet\n",
    "\n",
    "pdTweet.to_csv(\"crawler_tweet.csv\") \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Proximas etapas:\n",
    "## construir o bag of words  com a contagem ou importÃ¢ncia das palavras normalizadas e tokenizadas (calculo do tf-idf)\n",
    "##criar um dataset pandas com os resultados e a ultima coluna Ã© a classe (termoDeBusca)\n",
    "## utilizar classificadores variasdos e verificar qual tem a melhor acurÃ¡cia\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#TAREFAS RECOMENDADAS....\n",
    "\n",
    "#normalizar Todos os tweets;\n",
    "#Tokenizar os tweets\n",
    "#remover stopwords\n",
    "# calcular as contagens de ocorrÃªncias\n",
    "#selecionar as 3 palavras mais frequentes de cada classe (termoDeBusca)\n",
    "#fazer a tabela do dataframe pandas com a ultima coluna sendo a classe (termoDeBusca)\n",
    "#utilizar um (ou vÃ¡rios) classificadores para aprender \n",
    "\n",
    "#buscar um tweet qualquer (ou criar um frase) e testar...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nome</th>\n",
       "      <th>LocalizaÃ§Ã£o</th>\n",
       "      <th>Data</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>classe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellbandolero1</td>\n",
       "      <td>Bruxelas, BÃ©lgica</td>\n",
       "      <td>2020-09-19 18:08:16</td>\n",
       "      <td>RT @Stell_dos_Caros: Falsidade nÃ£o tem perdÃ£o ...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elias1costa</td>\n",
       "      <td>092</td>\n",
       "      <td>2020-09-19 18:08:14</td>\n",
       "      <td>@laurentinoheart @forumpandlr E a atuaÃ§Ã£o dela...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lyciferCeci</td>\n",
       "      <td>UberlÃ¢ndia, Brasil</td>\n",
       "      <td>2020-09-19 18:08:11</td>\n",
       "      <td>@amandabaseado n sei brincar perdÃ£o (COLOCA UM...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vandals_girl_</td>\n",
       "      <td>SÃ£o Paulo, Brasil</td>\n",
       "      <td>2020-09-19 18:08:09</td>\n",
       "      <td>Rimou atÃ© com o pedido de perdÃ£o que eu recebi...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunggiie</td>\n",
       "      <td>Everyone hides inside of the mask\\nëª¨ë‘ ê°€ë©´ ì†ì— ë‚´ë©´...</td>\n",
       "      <td>2020-09-19 18:08:07</td>\n",
       "      <td>ã…¤\\nã…¤perdÃ£o mais uma vez pela quantidade de twe...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loucarol_</td>\n",
       "      <td>VelÉ‘ris ğŸŒŒâœ¨</td>\n",
       "      <td>2020-09-19 18:08:06</td>\n",
       "      <td>RT @langtiffinxx: ontem eu expliquei pra minha...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Str8talker94</td>\n",
       "      <td>Lisboa, Portugal</td>\n",
       "      <td>2020-09-19 18:08:04</td>\n",
       "      <td>RT @VazHenriqueVaz1: O que foi feito ao NANI. ...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>v5stylinson</td>\n",
       "      <td>ğ–•ğ–—ğ–ğ–“ğ–ˆğ–Šğ–˜ğ–˜ ğ–•ğ–†ğ–—ğ–</td>\n",
       "      <td>2020-09-19 18:08:03</td>\n",
       "      <td>@Livpznton KKKKKKKKKK perdao amg nao queria me...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hmmsucrilhus</td>\n",
       "      <td></td>\n",
       "      <td>2020-09-19 18:07:58</td>\n",
       "      <td>RT @peachiuy: QUEM Ã‰ O T3ddy\\n\\npara o cego, Ã©...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>happyoonie</td>\n",
       "      <td>ğ–²ğ–§ğ–¨ğ–­ğ–¾ğ–¾, ğ–ºğ—Œğ—ğ—‹ğ—ˆ, ğ–»ğ—ğ—Œ, ğ—ğ—‘ğ—,\\nğ—‡ğ–¼ğ—, ğ–¾ğ—‘ğ—ˆ, ğ–¼ğ—‹ğ–ºğ—ğ—‚ğ—ğ—’ &amp; ...</td>\n",
       "      <td>2020-09-19 18:07:57</td>\n",
       "      <td>RT @peachiuy: QUEM Ã‰ O T3ddy\\n\\npara o cego, Ã©...</td>\n",
       "      <td>perdÃ£o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Nome                                        LocalizaÃ§Ã£o  \\\n",
       "0  Ellbandolero1                                  Bruxelas, BÃ©lgica   \n",
       "1    Elias1costa                                                092   \n",
       "2    lyciferCeci                                 UberlÃ¢ndia, Brasil   \n",
       "3  vandals_girl_                                  SÃ£o Paulo, Brasil   \n",
       "4       sunggiie  Everyone hides inside of the mask\\nëª¨ë‘ ê°€ë©´ ì†ì— ë‚´ë©´...   \n",
       "5      loucarol_                                         VelÉ‘ris ğŸŒŒâœ¨   \n",
       "6   Str8talker94                                   Lisboa, Portugal   \n",
       "7    v5stylinson                                     ğ–•ğ–—ğ–ğ–“ğ–ˆğ–Šğ–˜ğ–˜ ğ–•ğ–†ğ–—ğ–    \n",
       "8   hmmsucrilhus                                                      \n",
       "9     happyoonie  ğ–²ğ–§ğ–¨ğ–­ğ–¾ğ–¾, ğ–ºğ—Œğ—ğ—‹ğ—ˆ, ğ–»ğ—ğ—Œ, ğ—ğ—‘ğ—,\\nğ—‡ğ–¼ğ—, ğ–¾ğ—‘ğ—ˆ, ğ–¼ğ—‹ğ–ºğ—ğ—‚ğ—ğ—’ & ...   \n",
       "\n",
       "                 Data                                              Tweet  \\\n",
       "0 2020-09-19 18:08:16  RT @Stell_dos_Caros: Falsidade nÃ£o tem perdÃ£o ...   \n",
       "1 2020-09-19 18:08:14  @laurentinoheart @forumpandlr E a atuaÃ§Ã£o dela...   \n",
       "2 2020-09-19 18:08:11  @amandabaseado n sei brincar perdÃ£o (COLOCA UM...   \n",
       "3 2020-09-19 18:08:09  Rimou atÃ© com o pedido de perdÃ£o que eu recebi...   \n",
       "4 2020-09-19 18:08:07  ã…¤\\nã…¤perdÃ£o mais uma vez pela quantidade de twe...   \n",
       "5 2020-09-19 18:08:06  RT @langtiffinxx: ontem eu expliquei pra minha...   \n",
       "6 2020-09-19 18:08:04  RT @VazHenriqueVaz1: O que foi feito ao NANI. ...   \n",
       "7 2020-09-19 18:08:03  @Livpznton KKKKKKKKKK perdao amg nao queria me...   \n",
       "8 2020-09-19 18:07:58  RT @peachiuy: QUEM Ã‰ O T3ddy\\n\\npara o cego, Ã©...   \n",
       "9 2020-09-19 18:07:57  RT @peachiuy: QUEM Ã‰ O T3ddy\\n\\npara o cego, Ã©...   \n",
       "\n",
       "   classe  \n",
       "0  perdÃ£o  \n",
       "1  perdÃ£o  \n",
       "2  perdÃ£o  \n",
       "3  perdÃ£o  \n",
       "4  perdÃ£o  \n",
       "5  perdÃ£o  \n",
       "6  perdÃ£o  \n",
       "7  perdÃ£o  \n",
       "8  perdÃ£o  \n",
       "9  perdÃ£o  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tweets = tw.Cursor(api.search, \n",
    "                           q=termoDeBusca,\n",
    "                           lang=\"pt\",).items(10)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "localizacao = [[tweet.user.screen_name, tweet.user.location, tweet.created_at,tweet.text,termoDeBusca] for tweet in tweets]\n",
    "pdTweet = pd.DataFrame(data=localizacao, columns=['Nome', \"LocalizaÃ§Ã£o\",'Data','Tweet','classe'])\n",
    "\n",
    "pdTweet\n",
    " \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## com os tweets em mÃ£os, agora Ã© sÃ³ normalizar, fazer a tokenizaÃ§Ã£o/stemmizaÃ§Ã£o, remover stopwords criar o modelo de classificaÃ§Ã£o e voilat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#E se a gente mudar o tema para palavras de sentimentos?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

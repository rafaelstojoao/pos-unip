{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Não', 'se', 'pode', 'olhar', 'o', 'umbigo', 'e', 'contemplar', 'o', 'horizonte', 'ao', 'mesmo', 'tempo']\n"
     ]
    }
   ],
   "source": [
    "#tokenização\n",
    "\n",
    "import nltk\n",
    "\n",
    "texto = \"Não se pode olhar o umbigo e contemplar o horizonte ao mesmo tempo\"\n",
    "\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "tokens = tokenizer.tokenize(texto)\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "sometimes ADV adverb\n",
      "\n",
      "\n",
      "I PRON pronoun, personal\n",
      "\n",
      "\n",
      "think VERB verb, non-3rd person singular present\n",
      "\n",
      "\n",
      "I PRON pronoun, personal\n",
      "\n",
      "\n",
      "can VERB verb, modal auxiliary\n",
      "\n",
      "\n",
      "do AUX verb, base form\n",
      "\n",
      "\n",
      "everything PRON noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    " \n",
    "# python -m spacy download pt_core_news_sm\n",
    "# Mais corpus em: https://spacy.io/usage/models\n",
    "\n",
    "pln = spacy.load('en_core_web_sm')\n",
    "# pln = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "# frase = pln(\"Análise de uma frase criada pelo Rafael.\")\n",
    "frase = pln(\"sometimes I think I can do everything\")\n",
    "\n",
    "for token in frase:\n",
    "    print('\\n')\n",
    "    print(token.text, token.pos_,spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Esse', 'é', 'um', 'teste', 'para', 'testar', 'se', 'tudo', 'está', 'bem']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln = spacy.load(\"pt_core_news_sm\")\n",
    "\n",
    "texto2 = \"Esse é um teste para testar se tudo está bem\"\n",
    "\n",
    "frase = pln(texto2)\n",
    "\n",
    "\n",
    "palavras = []\n",
    "tipos = []\n",
    "\n",
    "for token in frase:\n",
    "\n",
    "    if token.text not in palavras:\n",
    "        palavras.append(token.text)\n",
    "        tipos.append(token.pos_)\n",
    "        \n",
    "palavras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PRON', 'AUX', 'DET', 'NOUN', 'SCONJ', 'VERB', 'SCONJ', 'PRON', 'AUX', 'ADV']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[400], [233], [226], [549], [420], [659], [216], [444], [557], [308]]\n",
      "[319, 238, 221, 320, 381, 303, 381, 319, 238, 219]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "palavrasEmNumeros = []\n",
    "tiposEmNumeros    = []\n",
    "\n",
    "\n",
    "for palavra in palavras:\n",
    "    valor = 0\n",
    "    for caracter in palavra:\n",
    "        valor += ord(caracter)\n",
    "#     print(valor)\n",
    "    palavrasEmNumeros.append([valor])\n",
    "\n",
    "for tipo in tipos:\n",
    "    valor = 0\n",
    "    for caracter in tipo:\n",
    "        valor += ord(caracter)\n",
    "#     print(valor)\n",
    "    tiposEmNumeros.append(valor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "print(palavrasEmNumeros)\n",
    "print(tiposEmNumeros)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "\n",
    "conjtoTreino = [palavrasEmNumeros,tiposEmNumeros]\n",
    "\n",
    "\n",
    "classificadorNaive = GaussianNB()\n",
    "classificadorNaive.fit(conjtoTreino[0],conjtoTreino[1])\n",
    "\n",
    "\n",
    "entradaTeste = [[550]]\n",
    "\n",
    "\n",
    "print(classificadorNaive.predict(entradaTeste))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

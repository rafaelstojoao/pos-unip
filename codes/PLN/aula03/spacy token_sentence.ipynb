{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu nome é Rafael. Hoje estamos trabalhando com crawler. Nós vamos virar mitos da data science\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "pln = spacy.load('pt')\n",
    "entrada = input()\n",
    "info = pln(entrada)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu nome é Rafael.\n",
      "Hoje estamos trabalhando com crawler.\n",
      "Nós vamos virar mitos da data science\n"
     ]
    }
   ],
   "source": [
    "#cada sentença da frase\n",
    "for sentenca in info.sents:\n",
    "    print(sentenca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu\n",
      "nome\n",
      "é\n",
      "Rafael\n",
      ".\n",
      "Hoje\n",
      "estamos\n",
      "trabalhando\n",
      "com\n",
      "crawler\n",
      ".\n",
      "Nós\n",
      "vamos\n",
      "virar\n",
      "mitos\n",
      "da\n",
      "data\n",
      "science\n"
     ]
    }
   ],
   "source": [
    "#cada termo da frase\n",
    "\n",
    "for token in info:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meu DET\n",
      "nome NOUN\n",
      "é AUX\n",
      "Rafael PROPN\n",
      ". PUNCT\n",
      "Hoje ADV\n",
      "estamos AUX\n",
      "trabalhando VERB\n",
      "com ADP\n",
      "crawler NOUN\n",
      ". PUNCT\n",
      "Nós PRON\n",
      "vamos AUX\n",
      "virar VERB\n",
      "mitos NOUN\n",
      "da DET\n",
      "data NOUN\n",
      "science ADJ\n"
     ]
    }
   ],
   "source": [
    "#cada termo da frase com seu tipo associado\n",
    "\n",
    "for token in info:\n",
    "    print(token,token.pos_)\n",
    "    \n",
    "    \n",
    "#NOUN:  substantivo\n",
    "#ADP:  preposição\n",
    "#PUNCT: pontuação\n",
    "#DET: determinante\n",
    "#VERB: verbo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A partir dessa entrada, como você selecionaria o melhor termo (token) para servir como uma busca no Google e indexar sites que tem conteúdo similar (web crawler)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale normalizar o texto?\n",
    "\n",
    "Vale lemmatizar?\n",
    "\n",
    "vale remover stop words?\n",
    "\n",
    "\n",
    "lembre-se que o spacy já tem módulo de lingua portuguesa, corpus e conversas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O que são androids\n",
      "Token: O, Lemma: O, TIPO: PRON\n",
      "Token: que, Lemma: que, TIPO: PRON\n",
      "Token: são, Lemma: ser, TIPO: AUX\n",
      "Token: androids, Lemma: androids, TIPO: VERB\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt_core_news_lg')\n",
    "\n",
    "entrada = input()\n",
    "info = pln(entrada)\n",
    "\n",
    "# doc = nlp('Eu só queria saber quando essa aula vai acabar...')\n",
    "\n",
    "for token in info:\n",
    "    print(\"Token: {}, Lemma: {}, TIPO: {}\".format(token, token.lemma_, token.pos_))\n",
    "    \n",
    "\n",
    "\n",
    "    #stopWrod\n",
    "    #remover os pontos\n",
    "    #normalizar\n",
    "    #selecionar os termos que você julga mais interessante..\n",
    "    #pode ser entidade (a gente tem codigo de reconhecimento de entidade)\n",
    "    #pode ser por tf-idf (a gente tbm tem codigo disso.)\n",
    "    #pode ser como você jultar melhor(só verbos, só pronomes, sõ substantivos ....)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pelase, insert a valid file path or -1 to run a simple example!\n",
      "-1\n",
      "ignoring data file, this example will run under dataset below:\n",
      "Dataset Loaded\n",
      "[['pão', 'muçarela', 'presunto'], ['pão', 'muçarela', 'presunto', 'mortadela', 'leite'], ['pão', 'muçarela', 'mortadela'], ['pão', 'presunto', 'mortadela', 'leite'], ['pão', 'muçarela', 'presunto', 'mortadela'], ['mortadela', 'pão'], ['ovo', 'leite']]\n",
      "Set the minimun support parameter: (recomended 0.025)\n",
      "0.025\n",
      "Set the minimun confidence parameter: (recomended 0.8)\n",
      "0.8\n",
      "generating Cand1\n",
      "Candidates of size: 1\n",
      "['leite']\n",
      "['mortadela']\n",
      "['muçarela']\n",
      "['ovo']\n",
      "['presunto']\n",
      "['pão']\n",
      "Validating candidates of size: 1\n",
      "minsup: 0.025\n",
      "Patterns: \n",
      "['leite'] Support: 0.42857142857142855\n",
      "['mortadela'] Support: 0.7142857142857143\n",
      "['muçarela'] Support: 0.5714285714285714\n",
      "['ovo'] Support: 0.14285714285714285\n",
      "['presunto'] Support: 0.5714285714285714\n",
      "['pão'] Support: 0.8571428571428571\n",
      "\n",
      "\n",
      " generating Cand_2\n",
      "['leite', 'mortadela']\n",
      "['leite', 'muçarela']\n",
      "['leite', 'ovo']\n",
      "['leite', 'presunto']\n",
      "['leite', 'pão']\n",
      "['mortadela', 'muçarela']\n",
      "['mortadela', 'ovo']\n",
      "['mortadela', 'presunto']\n",
      "['mortadela', 'pão']\n",
      "['muçarela', 'ovo']\n",
      "['muçarela', 'presunto']\n",
      "['muçarela', 'pão']\n",
      "['ovo', 'presunto']\n",
      "['ovo', 'pão']\n",
      "['presunto', 'pão']\n",
      "Validating candidates of size: 2\n",
      "minsup: 0.025\n",
      "Patterns: \n",
      "['leite', 'mortadela'] Support: 0.2857142857142857\n",
      "['leite', 'muçarela'] Support: 0.14285714285714285\n",
      "['leite', 'ovo'] Support: 0.14285714285714285\n",
      "['leite', 'presunto'] Support: 0.2857142857142857\n",
      "['leite', 'pão'] Support: 0.2857142857142857\n",
      "['mortadela', 'muçarela'] Support: 0.42857142857142855\n",
      "['mortadela', 'presunto'] Support: 0.42857142857142855\n",
      "['mortadela', 'pão'] Support: 0.7142857142857143\n",
      "['muçarela', 'presunto'] Support: 0.42857142857142855\n",
      "['muçarela', 'pão'] Support: 0.5714285714285714\n",
      "['presunto', 'pão'] Support: 0.5714285714285714\n",
      "\n",
      "\n",
      " generating Cand_3\n",
      "['leite', 'mortadela', 'muçarela']\n",
      "['leite', 'mortadela', 'ovo']\n",
      "['leite', 'mortadela', 'presunto']\n",
      "['leite', 'mortadela', 'pão']\n",
      "['leite', 'muçarela', 'ovo']\n",
      "['leite', 'muçarela', 'presunto']\n",
      "['leite', 'muçarela', 'pão']\n",
      "['leite', 'ovo', 'presunto']\n",
      "['leite', 'ovo', 'pão']\n",
      "['leite', 'presunto', 'pão']\n",
      "['mortadela', 'muçarela', 'presunto']\n",
      "['mortadela', 'muçarela', 'pão']\n",
      "['mortadela', 'presunto', 'pão']\n",
      "['muçarela', 'presunto', 'pão']\n",
      "Validating candidates of size: 3\n",
      "minsup: 0.025\n",
      "Patterns: \n",
      "['leite', 'mortadela', 'muçarela'] Support: 0.14285714285714285\n",
      "['leite', 'mortadela', 'presunto'] Support: 0.2857142857142857\n",
      "['leite', 'mortadela', 'pão'] Support: 0.2857142857142857\n",
      "['leite', 'muçarela', 'presunto'] Support: 0.14285714285714285\n",
      "['leite', 'muçarela', 'pão'] Support: 0.14285714285714285\n",
      "['leite', 'presunto', 'pão'] Support: 0.2857142857142857\n",
      "['mortadela', 'muçarela', 'presunto'] Support: 0.2857142857142857\n",
      "['mortadela', 'muçarela', 'pão'] Support: 0.42857142857142855\n",
      "['mortadela', 'presunto', 'pão'] Support: 0.42857142857142855\n",
      "['muçarela', 'presunto', 'pão'] Support: 0.42857142857142855\n",
      "\n",
      "\n",
      " generating Cand_4\n",
      "['leite', 'mortadela', 'muçarela', 'presunto']\n",
      "['leite', 'mortadela', 'muçarela', 'pão']\n",
      "['leite', 'mortadela', 'presunto', 'pão']\n",
      "['leite', 'muçarela', 'presunto', 'pão']\n",
      "['mortadela', 'muçarela', 'presunto', 'pão']\n",
      "Validating candidates of size: 4\n",
      "minsup: 0.025\n",
      "Patterns: \n",
      "['leite', 'mortadela', 'muçarela', 'presunto'] Support: 0.14285714285714285\n",
      "['leite', 'mortadela', 'muçarela', 'pão'] Support: 0.14285714285714285\n",
      "['leite', 'mortadela', 'presunto', 'pão'] Support: 0.2857142857142857\n",
      "['leite', 'muçarela', 'presunto', 'pão'] Support: 0.14285714285714285\n",
      "['mortadela', 'muçarela', 'presunto', 'pão'] Support: 0.2857142857142857\n",
      "\n",
      "\n",
      " generating Cand_5\n",
      "['leite', 'mortadela', 'muçarela', 'presunto', 'pão']\n",
      "Validating candidates of size: 5\n",
      "minsup: 0.025\n",
      "Patterns: \n",
      "['leite', 'mortadela', 'muçarela', 'presunto', 'pão'] Support: 0.14285714285714285\n",
      "Unable to build candidates...\n"
     ]
    }
   ],
   "source": [
    "# Este código é uma versão orientada a objetos do algoritmo de mineração de dados APRIORI\n",
    "# Identifica padrões, gera candidatoes e constrói regras de associação\n",
    "# implementada e idealizada por Rafael Stoffalette João.\n",
    "\n",
    "# find me on https://github.com/rafaelstojoao/apyori\n",
    "\n",
    "import numpy\n",
    "\n",
    "class rule:\n",
    "    def __init__(self):\n",
    "        self.support    = 0.0\n",
    "        self.confidence = 0.0\n",
    "        self.lift       = 0.0\n",
    "        self.X          = []\n",
    "        self.Y          = []\n",
    "        self.conviction = 0.0\n",
    "        self.allItems   = []\n",
    "        self.dataset    = []\n",
    "\n",
    "    def printRule(self):\n",
    "        print(self.X,'-->',self.Y,'sup: ',self.getSupport(),' conf:',self.getConfidence(), 'lift: ',self.lift, 'conviction: ',self.conviction)\n",
    "        fpRules = open(\"./rules.rul\",\"a+\")\n",
    "        fpRules.write(str(self.X)+'-->'+str(self.Y)+'sup: '+str(self.getSupport())+' conf:'+str(self.getConfidence())+ 'lift: '+str(self.lift)+ 'conviction: '+str(self.conviction)+\"\\n\")\n",
    "\n",
    "    def getConfidence(self):\n",
    "        return self.confidence\n",
    "\n",
    "    def getSupport(self):\n",
    "        return self.support\n",
    "\n",
    "    def setConfidence(self,conf):\n",
    "        self.confidence = conf\n",
    "\n",
    "    def setSupport(self,sup):\n",
    "        self.support = sup\n",
    "\n",
    "\n",
    "\n",
    "class itemset :\n",
    "    def __init__(self):\n",
    "        self.support    = 0.0\n",
    "        self.counting   = 0\n",
    "        self.items      = []\n",
    "\n",
    "    def getitems(self):\n",
    "        return self.items\n",
    "\n",
    "\n",
    "    def setSupport(self,dataSetSize):\n",
    "        self.suporte = self.counting / dataSetSize\n",
    "\n",
    "    def getSupport(self):\n",
    "        return self.suporte\n",
    "\n",
    "    def getCounting(self):\n",
    "        return self.counting\n",
    "\n",
    "    def setCounting(self,count):\n",
    "        self.counting = count\n",
    "\n",
    "    def increaseCounting(self):\n",
    "        self.counting =+ 1\n",
    "\n",
    "\n",
    "class Apryori:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.minSup     = 0.0\n",
    "        self.minConf    = 0.0\n",
    "        self.arq        = \"\"\n",
    "        self.dataset    = []\n",
    "        self.listadePadroes     = []\n",
    "        self.listadeCandidatos  = []\n",
    "        self.listRules          = []\n",
    "\n",
    "    def loadDataSetFromFile(self, path):\n",
    "        import csv\n",
    "        data =[]\n",
    "        with open(path) as csvfile:\n",
    "            data = list(csv.reader(csvfile))\n",
    "            self.dataset = sorted(data)\n",
    "\n",
    "        print(len(self.dataset))\n",
    "        print(self.dataset)\n",
    "        return self.dataset\n",
    "\n",
    "\n",
    "    def loadDataSet(self):\n",
    "       print('Dataset Loaded')\n",
    "       return [['pão','muçarela','presunto'],\n",
    "               ['pão','muçarela','presunto','mortadela', 'leite'],\n",
    "               ['pão','muçarela','mortadela'],\n",
    "               ['pão','presunto','mortadela','leite'],\n",
    "               ['pão','muçarela','presunto','mortadela'],\n",
    "               ['mortadela','pão'],\n",
    "               ['ovo','leite']]\n",
    "        # return [['leite','pão'],['pão','manteiga'],['cerveja'],['leite','pão','manteiga'],['pão']  ]\n",
    "\n",
    "    def combinaItens(self,elem,listaCombinar):\n",
    "        combinados =[]\n",
    "        print('combinar')\n",
    "        print(elem)\n",
    "        print('com')\n",
    "        print(listaCombinar)\n",
    "        for item in listaCombinar:\n",
    "            combinados.append([elem,item])\n",
    "        return combinados\n",
    "\n",
    "\n",
    "    def aprioriGen(self,i):\n",
    "        if(i == 0):\n",
    "            print('generating Cand1')\n",
    "            itemsTam1 = []\n",
    "            for transaction in self.dataset:\n",
    "                for item in transaction:\n",
    "                     if item not in itemsTam1:\n",
    "                        itemsTam1.append(item)\n",
    "            itemsTam1.sort()\n",
    "            listaCandidatostemp = []\n",
    "            for item in itemsTam1: #é preciso transformar cada item em um candidato.\n",
    "                cand  = itemset()\n",
    "                cand.items = [item]\n",
    "                listaCandidatostemp.append(cand)\n",
    "            self.listadeCandidatos.append(listaCandidatostemp)\n",
    "\n",
    "        elif len(self.listadePadroes[i - 1]) <= 1:\n",
    "            print('Unable to build candidates...')\n",
    "            self.listadeCandidatos.append([])\n",
    "            return\n",
    "        else:\n",
    "            print('\\n\\n generating Cand_' + str(i + 1))\n",
    "\n",
    "            listaPadroes =[]\n",
    "            listaCandidatos = []\n",
    "            for padrao in self.listadePadroes[i-1]:\n",
    "                listaPadroes.append(padrao.items)\n",
    "\n",
    "            for i in range(len(listaPadroes)):\n",
    "                padrao = listaPadroes[i]\n",
    "                resto = listaPadroes[i+1:]\n",
    "\n",
    "                for itset in resto:\n",
    "                    L1 = padrao[:-1]\n",
    "                    L2 = itset[:-1]\n",
    "\n",
    "                    if L1 == L2:\n",
    "                        candidato = sorted(list(set(padrao) | set(itset)))\n",
    "                        # if(len(candidato) >= 10):\n",
    "                        #     print(candidato)\n",
    "                        cand = itemset()\n",
    "                        cand.items =candidato\n",
    "                        listaCandidatos.append(cand)\n",
    "            self.listadeCandidatos.append(listaCandidatos)\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "    def validaCandidatos(self,i):\n",
    "        print('Validating candidates of size: ' + str(i+1))\n",
    "        print('minsup: '+str(self.minSup))\n",
    "        fp = open(\"./patterns.patt\", \"a+\")\n",
    "        if i==0: # se são itens unitários para verificar\n",
    "            for reg in self.dataset:\n",
    "                for cand in self.listadeCandidatos[i]:\n",
    "                    if set(cand.items).intersection(reg):\n",
    "                         cand.counting += 1\n",
    "            listaPadroes = []\n",
    "\n",
    "            for cand in self.listadeCandidatos[i]:\n",
    "                cand.suporte = cand.counting/self.tamanhoDataset\n",
    "                if(cand.suporte >= self.minSup):\n",
    "                    listaPadroes.append(cand)\n",
    "                    fp.write(str(cand.items) + ' support: ' + str(cand.suporte) + \"\\n\")\n",
    "\n",
    "            return listaPadroes\n",
    "\n",
    "        else:\n",
    "            for reg in self.dataset:\n",
    "                for cand in self.listadeCandidatos[i]:\n",
    "\n",
    "                    if self.sublist(cand.items,reg):\n",
    "                        cand.counting+=1\n",
    "\n",
    "            listaPadroes = []\n",
    "            for cand in self.listadeCandidatos[i]:\n",
    "                cand.suporte = cand.counting / self.tamanhoDataset\n",
    "                if (cand.suporte >= self.minSup):\n",
    "                    listaPadroes.append(cand)\n",
    "                    fp.write(str(cand.items) + ' support: ' + str(cand.suporte) + \"\\n\")\n",
    "            return listaPadroes\n",
    "\n",
    "    def sublist(self, lst1, lst2):\n",
    "        condBool = True\n",
    "        for elem in lst1:\n",
    "            if elem not in lst2:\n",
    "                condBool = False\n",
    "        return condBool\n",
    "\n",
    "    \n",
    "\n",
    "    def estimateSupport(self,listitems):\n",
    "        count =0\n",
    "        for reg in self.dataset:\n",
    "            if (set(listitems).intersection(reg) == set(listitems)):\n",
    "                count += 1\n",
    "        return count/self.tamanhoDataset\n",
    "\n",
    "    \n",
    "\n",
    "    def   apriori(self,dataset,minsup=None,minconf=None):\n",
    "        self.dataset = dataset\n",
    "        self.tamanhoDataset = len(self.dataset)\n",
    "        self.minSup  = minsup\n",
    "        self.minConf = minconf\n",
    "\n",
    "        i = 0\n",
    "        self.aprioriGen(0)\n",
    "        print('Candidates of size: '+str(i+1))\n",
    "        for itemsetCandidato in self.listadeCandidatos[0]:\n",
    "              print(itemsetCandidato.items)\n",
    "\n",
    "\n",
    "        while (self.listadeCandidatos[i]):\n",
    "            self.listadePadroes.append(self.validaCandidatos(i))\n",
    "\n",
    "            print('Patterns: ')\n",
    "            # if(len(self.listadePadroes[i][1].items) >= 8):\n",
    "            fp = open(\"patterns.csv\",\"a+\")\n",
    "\n",
    "            for padrao in self.listadePadroes[i]:\n",
    "                print(str(padrao.items)+' Support: '+str(padrao.suporte))\n",
    "                fp.write(str(padrao.items)+' Support: '+str(padrao.suporte)+\"\\n\")\n",
    "            i += 1\n",
    "            self.aprioriGen(i)\n",
    "            for cand in self.listadeCandidatos[i]:\n",
    "                print(cand.items)\n",
    "\n",
    "#         self.generateRules()\n",
    "\n",
    "#         for regra in self.listRules:\n",
    "#             regra.printRule()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    apr = Apryori()\n",
    "    print(\"pelase, insert a valid file path or -1 to run a simple example!\")\n",
    "    op = str(input())\n",
    "    if(op == '-1'):\n",
    "        print(\"ignoring data file, this example will run under dataset below:\")\n",
    "        dataset = apr.loadDataSet()\n",
    "        print(dataset)\n",
    "    else:\n",
    "        print(\"This execution will run under \"+ op+ \"file\")\n",
    "        dataset = apr.loadDataSetFromFile(op)\n",
    "\n",
    "    print(\"Set the minimun support parameter: (recomended 0.025)\")\n",
    "    minsup = float(input())\n",
    "    \n",
    "    apr.apriori(dataset,minsup,minconf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

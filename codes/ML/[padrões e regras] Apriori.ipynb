{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código é uma versão orientada a objetos do algoritmo de mineração de dados APRIORI\n",
    "# Identifica padrões, gera candidatoes e constrói regras de associação\n",
    "# implementada e idealizada por Rafael Stoffalette João.\n",
    "\n",
    "# find me on https://github.com/rafaelstojoao/AprioriPy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pelase, insert a valid file path or -1 to run a simple example!\n",
      "-1\n",
      "ignoring data file, this example will run under dataset below:\n",
      "Dataset Loaded\n",
      "[['A', 'B', 'C'], ['A', 'B', 'C', 'D', 'E'], ['A', 'C', 'D'], ['A', 'C', 'D', 'E'], ['A', 'B', 'C', 'D']]\n",
      "Set the minimun support parameter: (recomended 0.025)\n",
      "0.025\n",
      "Set the minimun confidence parameter: (recomended 0.8)\n",
      "0.7\n",
      "generating Cand1\n",
      "candidatos de tamanho: 1\n",
      "['A']\n",
      "['B']\n",
      "['C']\n",
      "['D']\n",
      "['E']\n",
      "Validando candidatos de tamanho: 1\n",
      "minsup: 0.025\n",
      "padrões: \n",
      "['A'] suporte: 1.0\n",
      "['B'] suporte: 0.6\n",
      "['C'] suporte: 1.0\n",
      "['D'] suporte: 0.8\n",
      "['E'] suporte: 0.4\n",
      "\n",
      "\n",
      " generating Cand_2\n",
      "['A', 'B']\n",
      "['A', 'C']\n",
      "['A', 'D']\n",
      "['A', 'E']\n",
      "['B', 'C']\n",
      "['B', 'D']\n",
      "['B', 'E']\n",
      "['C', 'D']\n",
      "['C', 'E']\n",
      "['D', 'E']\n",
      "Validando candidatos de tamanho: 2\n",
      "minsup: 0.025\n",
      "padrões: \n",
      "['A', 'B'] suporte: 0.6\n",
      "['A', 'C'] suporte: 1.0\n",
      "['A', 'D'] suporte: 0.8\n",
      "['A', 'E'] suporte: 0.4\n",
      "['B', 'C'] suporte: 0.6\n",
      "['B', 'D'] suporte: 0.4\n",
      "['B', 'E'] suporte: 0.2\n",
      "['C', 'D'] suporte: 0.8\n",
      "['C', 'E'] suporte: 0.4\n",
      "['D', 'E'] suporte: 0.4\n",
      "\n",
      "\n",
      " generating Cand_3\n",
      "['A', 'B', 'C']\n",
      "['A', 'B', 'D']\n",
      "['A', 'B', 'E']\n",
      "['A', 'C', 'D']\n",
      "['A', 'C', 'E']\n",
      "['A', 'D', 'E']\n",
      "['B', 'C', 'D']\n",
      "['B', 'C', 'E']\n",
      "['B', 'D', 'E']\n",
      "['C', 'D', 'E']\n",
      "Validando candidatos de tamanho: 3\n",
      "minsup: 0.025\n",
      "padrões: \n",
      "['A', 'B', 'C'] suporte: 0.6\n",
      "['A', 'B', 'D'] suporte: 0.4\n",
      "['A', 'B', 'E'] suporte: 0.2\n",
      "['A', 'C', 'D'] suporte: 0.8\n",
      "['A', 'C', 'E'] suporte: 0.4\n",
      "['A', 'D', 'E'] suporte: 0.4\n",
      "['B', 'C', 'D'] suporte: 0.4\n",
      "['B', 'C', 'E'] suporte: 0.2\n",
      "['B', 'D', 'E'] suporte: 0.2\n",
      "['C', 'D', 'E'] suporte: 0.4\n",
      "\n",
      "\n",
      " generating Cand_4\n",
      "['A', 'B', 'C', 'D']\n",
      "['A', 'B', 'C', 'E']\n",
      "['A', 'B', 'D', 'E']\n",
      "['A', 'C', 'D', 'E']\n",
      "['B', 'C', 'D', 'E']\n",
      "Validando candidatos de tamanho: 4\n",
      "minsup: 0.025\n",
      "padrões: \n",
      "['A', 'B', 'C', 'D'] suporte: 0.4\n",
      "['A', 'B', 'C', 'E'] suporte: 0.2\n",
      "['A', 'B', 'D', 'E'] suporte: 0.2\n",
      "['A', 'C', 'D', 'E'] suporte: 0.4\n",
      "['B', 'C', 'D', 'E'] suporte: 0.2\n",
      "\n",
      "\n",
      " generating Cand_5\n",
      "['A', 'B', 'C', 'D', 'E']\n",
      "Validando candidatos de tamanho: 5\n",
      "minsup: 0.025\n",
      "padrões: \n",
      "['A', 'B', 'C', 'D', 'E'] suporte: 0.2\n",
      "Não se pode construir mais candidatos\n",
      "Generating rules\n",
      "5\n",
      "['A'] --> ['C'] sup:  1.0  conf: 1.0 lift:  1.0 conviction:  0.0\n",
      "['A'] --> ['D'] sup:  0.8  conf: 0.8 lift:  1.0 conviction:  1.0\n",
      "['B'] --> ['C'] sup:  0.6  conf: 1.0 lift:  1.0 conviction:  0.0\n",
      "['C'] --> ['D'] sup:  0.8  conf: 0.8 lift:  1.0 conviction:  1.0\n",
      "['A', 'B'] --> ['C'] sup:  0.6  conf: 1.0 lift:  1.0 conviction:  0.0\n",
      "['A'] --> ['C', 'D'] sup:  0.8  conf: 0.8 lift:  1.0 conviction:  1.0\n",
      "['A', 'C'] --> ['D'] sup:  0.8  conf: 0.8 lift:  1.0 conviction:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Este código é uma versão orientada a objetos do algoritmo de mineração de dados APRIORI\n",
    "# Identifica padrões, gera candidatoes e constrói regras de associação\n",
    "\n",
    "import numpy\n",
    "\n",
    "class rule:\n",
    "    def __init__(self):\n",
    "        self.support    = 0.0\n",
    "        self.confidence = 0.0\n",
    "        self.lift       = 0.0\n",
    "        self.X          = []\n",
    "        self.Y          = []\n",
    "        self.conviction = 0.0\n",
    "        self.allItems   = []\n",
    "        self.dataset    = []\n",
    "\n",
    "    def printRule(self):\n",
    "        print(self.X,'-->',self.Y,'sup: ',self.getSupport(),' conf:',self.getConfidence(), 'lift: ',self.lift, 'conviction: ',self.conviction)\n",
    "        fpRules = open(\"./rules.rul\",\"a+\")\n",
    "        fpRules.write(str(self.X)+'-->'+str(self.Y)+'sup: '+str(self.getSupport())+' conf:'+str(self.getConfidence())+ 'lift: '+str(self.lift)+ 'conviction: '+str(self.conviction)+\"\\n\")\n",
    "\n",
    "    def getConfidence(self):\n",
    "        return self.confidence\n",
    "\n",
    "    def getSupport(self):\n",
    "        return self.support\n",
    "\n",
    "    def setConfidence(self,conf):\n",
    "        self.confidence = conf\n",
    "\n",
    "    def setSupport(self,sup):\n",
    "        self.support = sup\n",
    "\n",
    "\n",
    "\n",
    "class itemset :\n",
    "    def __init__(self):\n",
    "        self.support    = 0.0\n",
    "        self.counting   = 0\n",
    "        self.items      = []\n",
    "\n",
    "    def getitems(self):\n",
    "        return self.items\n",
    "\n",
    "\n",
    "    def setSupport(self,dataSetSize):\n",
    "        self.suporte = self.counting / dataSetSize\n",
    "\n",
    "    def getSupport(self):\n",
    "        return self.suporte\n",
    "\n",
    "    def getCounting(self):\n",
    "        return self.counting\n",
    "\n",
    "    def setCounting(self,count):\n",
    "        self.counting = count\n",
    "\n",
    "    def increaseCounting(self):\n",
    "        self.counting =+ 1\n",
    "\n",
    "\n",
    "class Apryori:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.minSup     = 0.0\n",
    "        self.minConf    = 0.0\n",
    "        self.arq        = \"\"\n",
    "        self.dataset    = []\n",
    "        self.listadePadroes     = []\n",
    "        self.listadeCandidatos  = []\n",
    "        self.listRules          = []\n",
    "\n",
    "    def loadDataSetFromFile(self, path):\n",
    "        import csv\n",
    "        data =[]\n",
    "        with open(path) as csvfile:\n",
    "            data = list(csv.reader(csvfile))\n",
    "            self.dataset = sorted(data)\n",
    "\n",
    "        print(len(self.dataset))\n",
    "        print(self.dataset)\n",
    "        return self.dataset\n",
    "\n",
    "\n",
    "    def loadDataSet(self):\n",
    "       print('Dataset Loaded')\n",
    "       return [['A','B','C'],\n",
    "               ['A','B','C','D', 'E'],\n",
    "               ['A','C','D'],\n",
    "               ['A','C','D','E'],\n",
    "               ['A','B','C','D']]\n",
    "        # return [['leite','pão'],['pão','manteiga'],['cerveja'],['leite','pão','manteiga'],['pão']  ]\n",
    "\n",
    "    def combinaItens(self,elem,listaCombinar):\n",
    "        combinados =[]\n",
    "        print('combinar')\n",
    "        print(elem)\n",
    "        print('com')\n",
    "        print(listaCombinar)\n",
    "        for item in listaCombinar:\n",
    "            combinados.append([elem,item])\n",
    "        return combinados\n",
    "\n",
    "\n",
    "    def aprioriGen(self,i):\n",
    "        if(i == 0):\n",
    "            print('generating Cand1')\n",
    "            itemsTam1 = []\n",
    "            for transaction in self.dataset:\n",
    "                for item in transaction:\n",
    "                     if item not in itemsTam1:\n",
    "                        itemsTam1.append(item)\n",
    "            itemsTam1.sort()\n",
    "            listaCandidatostemp = []\n",
    "            for item in itemsTam1: #é preciso transformar cada item em um candidato.\n",
    "                cand  = itemset()\n",
    "                cand.items = [item]\n",
    "                listaCandidatostemp.append(cand)\n",
    "            self.listadeCandidatos.append(listaCandidatostemp)\n",
    "\n",
    "        elif len(self.listadePadroes[i - 1]) <= 1:\n",
    "            print('Não se pode construir mais candidatos')\n",
    "            self.listadeCandidatos.append([])\n",
    "            return\n",
    "        else:\n",
    "            print('\\n\\n generating Cand_' + str(i + 1))\n",
    "\n",
    "            listaPadroes =[]\n",
    "            listaCandidatos = []\n",
    "            for padrao in self.listadePadroes[i-1]:\n",
    "                listaPadroes.append(padrao.items)\n",
    "\n",
    "            for i in range(len(listaPadroes)):\n",
    "                padrao = listaPadroes[i]\n",
    "                resto = listaPadroes[i+1:]\n",
    "\n",
    "                for itset in resto:\n",
    "                    L1 = padrao[:-1]\n",
    "                    L2 = itset[:-1]\n",
    "\n",
    "                    if L1 == L2:\n",
    "                        candidato = sorted(list(set(padrao) | set(itset)))\n",
    "                        # if(len(candidato) >= 10):\n",
    "                        #     print(candidato)\n",
    "                        cand = itemset()\n",
    "                        cand.items =candidato\n",
    "                        listaCandidatos.append(cand)\n",
    "            self.listadeCandidatos.append(listaCandidatos)\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "    def validaCandidatos(self,i):\n",
    "        print('Validando candidatos de tamanho: ' + str(i+1))\n",
    "        print('minsup: '+str(self.minSup))\n",
    "        fp = open(\"./padroes.patt\", \"a+\")\n",
    "        if i==0: # se são itens unitários para verificar\n",
    "            for reg in self.dataset:\n",
    "                for cand in self.listadeCandidatos[i]:\n",
    "                    if set(cand.items).intersection(reg):\n",
    "                         cand.counting += 1\n",
    "            listaPadroes = []\n",
    "\n",
    "            for cand in self.listadeCandidatos[i]:\n",
    "                cand.suporte = cand.counting/self.tamanhoDataset\n",
    "                if(cand.suporte >= self.minSup):\n",
    "                    listaPadroes.append(cand)\n",
    "                    fp.write(str(cand.items) + ' suporte: ' + str(cand.suporte) + \"\\n\")\n",
    "\n",
    "            return listaPadroes\n",
    "\n",
    "        else:\n",
    "            for reg in self.dataset:\n",
    "                for cand in self.listadeCandidatos[i]:\n",
    "\n",
    "                    if self.sublist(cand.items,reg):\n",
    "                        cand.counting+=1\n",
    "\n",
    "            listaPadroes = []\n",
    "            for cand in self.listadeCandidatos[i]:\n",
    "                cand.suporte = cand.counting / self.tamanhoDataset\n",
    "                if (cand.suporte >= self.minSup):\n",
    "                    listaPadroes.append(cand)\n",
    "                    fp.write(str(cand.items) + ' suporte: ' + str(cand.suporte) + \"\\n\")\n",
    "            return listaPadroes\n",
    "\n",
    "    def sublist(self, lst1, lst2):\n",
    "        condBool = True\n",
    "        for elem in lst1:\n",
    "            if elem not in lst2:\n",
    "                condBool = False\n",
    "        return condBool\n",
    "\n",
    "    def geraRegra(self,itset):\n",
    "        listaRegras = []\n",
    "        tamItemset = len(itset.items)\n",
    "        for i in range(0,tamItemset-1):\n",
    "            R =rule()\n",
    "            R.X = itset.items[:i+1]\n",
    "            R.Y = itset.items[i+1:]\n",
    "            listaRegras.append(R)\n",
    "        return listaRegras\n",
    "\n",
    "\n",
    "\n",
    "    def printRules(self):\n",
    "        for rul in self.listRules:\n",
    "            print(str(rul.X) + '--> ' + str(rul.Y))\n",
    "\n",
    "\n",
    "    def estimateSupport(self,listitems):\n",
    "        count =0\n",
    "        for reg in self.dataset:\n",
    "            if (set(listitems).intersection(reg) == set(listitems)):\n",
    "                count += 1\n",
    "        return count/self.tamanhoDataset\n",
    "\n",
    "    def validateRule(self,ruleSetCandidate):\n",
    "        listValidRules = []\n",
    "\n",
    "        for rule in ruleSetCandidate:\n",
    "            itemsRule = itemset()\n",
    "            itemsRule.items = sorted(numpy.unique(rule.X + list(set(rule.Y) - set(rule.X))))\n",
    "            rule.allItems = itemsRule\n",
    "            rule.setSupport(self.estimateSupport(itemsRule.items))\n",
    "\n",
    "            X = itemset()\n",
    "            Y = itemset()\n",
    "\n",
    "            X.items = rule.X\n",
    "            Y.items = rule.Y\n",
    "\n",
    "            X.support = self.estimateSupport(X.items)\n",
    "            Y.support = self.estimateSupport(Y.items)\n",
    "\n",
    "            #confidence measure:  sup(XUY)/sup(X)\n",
    "            rule.setConfidence(round(rule.getSupport()/X.support,3))\n",
    "\n",
    "            if rule.getConfidence() >= self.minConf:\n",
    "                listValidRules.append(rule)\n",
    "\n",
    "                # set lift\n",
    "                try:\n",
    "                    rule.lift = round(rule.getSupport() / (Y.support * X.support),3)\n",
    "                except ZeroDivisionError:\n",
    "                    rule.lift = 0.0\n",
    "\n",
    "                try:\n",
    "                    rule.conviction = round((1.0 - Y.support) / (1.0 - rule.confidence),3)\n",
    "                except ZeroDivisionError:\n",
    "                    rule.conviction = 0.0\n",
    "\n",
    "        return listValidRules\n",
    "\n",
    "    def generateRules(self):\n",
    "        print('Generating rules')\n",
    "        ciclos = len(self.listadePadroes)\n",
    "        print(ciclos)\n",
    "        for i in range(1,ciclos):\n",
    "            regrasValidadas =[]\n",
    "            padroes = self.listadePadroes[i]\n",
    "            for itset in padroes:\n",
    "                listaRegras = self.geraRegra(itset)\n",
    "                regrasValidadas+=self.validateRule(listaRegras)\n",
    "            self.listRules+= regrasValidadas\n",
    "\n",
    "\n",
    "\n",
    "    def   apriori(self,dataset,minsup=None,minconf=None):\n",
    "        self.dataset = dataset\n",
    "        self.tamanhoDataset = len(self.dataset)\n",
    "        self.minSup  = minsup\n",
    "        self.minConf = minconf\n",
    "\n",
    "        i = 0\n",
    "        self.aprioriGen(0)\n",
    "        print('candidatos de tamanho: '+str(i+1))\n",
    "        for itemsetCandidato in self.listadeCandidatos[0]:\n",
    "              print(itemsetCandidato.items)\n",
    "\n",
    "\n",
    "        while (self.listadeCandidatos[i]):\n",
    "            self.listadePadroes.append(self.validaCandidatos(i))\n",
    "\n",
    "            print('padrões: ')\n",
    "            # if(len(self.listadePadroes[i][1].items) >= 8):\n",
    "            fp = open(\"padroes.csv\",\"a+\")\n",
    "\n",
    "            for padrao in self.listadePadroes[i]:\n",
    "                print(str(padrao.items)+' suporte: '+str(padrao.suporte))\n",
    "                fp.write(str(padrao.items)+' suporte: '+str(padrao.suporte)+\"\\n\")\n",
    "            i += 1\n",
    "            self.aprioriGen(i)\n",
    "            for cand in self.listadeCandidatos[i]:\n",
    "                print(cand.items)\n",
    "\n",
    "        self.generateRules()\n",
    "\n",
    "        for regra in self.listRules:\n",
    "            regra.printRule()\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    apr = Apryori()\n",
    "    print(\"pelase, insert a valid file path or -1 to run a simple example!\")\n",
    "    op = str(input())\n",
    "    if(op == '-1'):\n",
    "        print(\"ignoring data file, this example will run under dataset below:\")\n",
    "        dataset = apr.loadDataSet()\n",
    "        print(dataset)\n",
    "    else:\n",
    "        print(\"This execution will run under \"+ op+ \"file\")\n",
    "        dataset = apr.loadDataSetFromFile(op)\n",
    "\n",
    "    print(\"Set the minimun support parameter: (recomended 0.025)\")\n",
    "    minsup = float(input())\n",
    "    print(\"Set the minimun confidence parameter: (recomended 0.8)\")\n",
    "    minconf = float(input())\n",
    "    apr.apriori(dataset,minsup,minconf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
